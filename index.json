[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m an MD/PhD student at the University of Washington\u0026rsquo;s MSTP. I\u0026rsquo;m currently in the PhD phase of my training at the Allen School of Computer Science and Engineering, where I\u0026rsquo;m being advised by Su-In Lee. My research mostly focuses on two separate topics in machine learning: developing methods for feature attribution and learning models that are robust to domain shift. I\u0026rsquo;m interested in applications ranging from precision oncology, to molecular biology, to radiology.\nWhen I\u0026rsquo;m not in lab, you can probably find me biking, running, or hiking with my partner Sam and our dog Toby.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/joseph-d.-janizek/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/joseph-d.-janizek/","section":"authors","summary":"I\u0026rsquo;m an MD/PhD student at the University of Washington\u0026rsquo;s MSTP. I\u0026rsquo;m currently in the PhD phase of my training at the Allen School of Computer Science and Engineering, where I\u0026rsquo;m being advised by Su-In Lee.","tags":null,"title":"Joseph D. Janizek","type":"authors"},{"authors":[],"categories":[],"content":"","date":1599331202,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599331202,"objectID":"a4db87dc3e5e00271af74c524693d64c","permalink":"/publication/adae/","publishdate":"2020-07-09T14:40:02-04:00","relpermalink":"/publication/adae/","section":"publication","summary":"Published in __Bioinformatics__, selected for oral presentation at the _European Conference on Computational Biology_ 2020.","tags":[],"title":"Adversarial Deconfounding Autoencoder for Learning Robust Gene Expression Embeddings","type":"publication"},{"authors":[],"categories":null,"content":"","date":1595462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595462400,"objectID":"22caba1ef5666a98e51e55cc06070c17","permalink":"/talk/cxr_adv/","publishdate":"2020-07-09T14:23:31-04:00","relpermalink":"/talk/cxr_adv/","section":"talk","summary":"Spotlight presentation at ACM CHIL 2020 for research paper \"An adversarial approach for the robust classification of pneumonia from chest radiographs\"","tags":[],"title":"Learning to robustly classify chest radiographs","type":"talk"},{"authors":[],"categories":[],"content":"","date":1595011127,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595011127,"objectID":"901562ff1a410a4cb18a50ca780f2e7f","permalink":"/publication/true_to_model_true_to_data/","publishdate":"2020-07-09T14:38:47-04:00","relpermalink":"/publication/true_to_model_true_to_data/","section":"publication","summary":"Short paper selected for spotlight presentation at the __ICML Workshop on Human Interpretability__ 2020.","tags":[],"title":"True to the model, or true to the data?","type":"publication"},{"authors":[],"categories":null,"content":"","date":1594944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594944000,"objectID":"7cfa5d1bcff16c8966a869541059d4e2","permalink":"/talk/true_to_model_true_to_data/","publishdate":"2020-07-09T14:29:47-04:00","relpermalink":"/talk/true_to_model_true_to_data/","section":"talk","summary":"Spotlight presentation at ICML WHI 2020 discussing the selection of set function when using Shapley values for model explanation.","tags":[],"title":"True to the model, or true to the data?","type":"talk"},{"authors":[],"categories":[],"content":"This is (hopefully) an intuitive description of our new feature interaction method, Integrated Hessians. If you want a deeper dive into the math, you can check out our paper on arXiv (written with my co-author Pascal Sturmfels and our advisor Su-In Lee). If you just want the code, you can check out our repo on GitHub. Please feel free to reach out with any questions or issues, especially if you want to apply Integrated Hessians to your own models!\nTable of Contents  Intro: Why would I want to find feature interactions? Our approach: Integrated Hessians Why can\u0026rsquo;t I just look at the Hessian? One weird trick to find interaction in ReLU networks\u0026hellip; Hyperbole and a Different Type of Saturation Conclusions   Intro: Why would I want to find feature interactions? One of the most popular areas of research in the field of explainable AI has been feature attribution methods, which aim to identify the input features that have the greatest impact on a machine learning model\u0026rsquo;s predictions. While these methods have been helpful for a wide variety of applications, users may desire a greater degree of insight into model performance than a single scalar value per feature can provide.\nFor example, a recent survey of industry data scientists using explainable AI in deployment showed that many would like to be able to identify feature interactions – in the words of one of the data scientists interviewed, the ability to identify how “feature A will impact feature B.” To make the idea of feature interaction more concrete, we can consider a two-feature model of the very deadly Hypothetical Disease. In this model, the risk of Hypothetical Disease is determined solely by a patient\u0026rsquo;s gender and age. We can visualize the risk of disease for two patients, where Patient 1 is a 67 year-old man and Patient 2 is a 67 year-old woman. Looking at the overall risk, we can see that Patient 1 has a significantly higher overall risk than Patient 2. To understand why, we can examine the feature attributions for this model.\n  Hypothetical disease risk attribution   Looking at the attributions for gender, we see that Patient 1\u0026rsquo;s male gender contributes more risk than Patient 2\u0026rsquo;s female gender. This makes intuitive sense, as gender differences are often associated with different risks of disease.1 When we look at the age attribution, however, we can see that something more interesting is happening. While both patients are 67 years old, Patient 1 has more risk from being 67 than Patient 2. This is due to a feature interaction between gender and age. In this model, being a man not only carries a higher risk of disease than being a woman, it also increases the amount of risk due to age.\n  Hypothetical disease risk interaction   While it is pretty easy to figure out that gender is the feature interacting with age in this 2-feature model, trying to determine which features are responsible for interactions in high-dimensional data modeled with deep neural networks is more complicated. The next section will detail how we tried to solve this problem.\nOur approach: Integrated Hessians The data scientist mentioned in the introduction who wanted to understand how \u0026ldquo;feature A will impact feature B\u0026rdquo; provides the clearest motivation for our method. In essence, while feature attribution methods aim to explain how the value of each input feature will impact a model\u0026rsquo;s output, our feature interaction method aims to explain how the value of each input feature will impact each other feature\u0026rsquo;s attribution.\nOne of the most popular methods for feature attribution for neural networks is Integrated Gradients.2 This method attributes a scalar importance to each feature $i$ by averaging the gradients of the model $f$ along a linear interpolation path between a baseline $x'$ and a target sample $x$: $$ \\phi_i (x) = (x_i - x\u0026rsquo;_i) \\times \\int_{\\alpha=0}^{1} \\frac{ \\partial f(x\u0026rsquo; + \\alpha(x-x\u0026rsquo;)) }{\\partial x_i} d\\alpha. $$\nThe core insight of our approach was to realize that Integrated Gradients (which can be used to explain any differentiable function $f : \\mathbb{R}^N \\mapsto \\mathbb{R}$) is itself a differentiable function $ \\phi_i : \\mathbb{R}^N \\mapsto \\mathbb{R}$.3 Therefore, we can apply Integrated Gradients to itself to identify feature interactions of the exact form desired by our data scientist. The Integrated Hessians interaction between features $i$ and $j$ is the impact of Feature $i$ on Feature $j$'s attribution: $$ \\Gamma_{i,j} = \\phi_i (\\phi_j(x)). $$ This is the inspiration for the title of our paper, \u0026ldquo;Explaining Explanations,\u0026rdquo; since our interactions are found by explaining the output of an explanation method.3 This captures a human-intuitive definition of the interaction between two features: the interaction is the impact these features have on each other\u0026rsquo;s importance.\nWhy can\u0026rsquo;t I just look at the Hessian? To provide some more context as to why you might want to use Integrated Hessians to find feature interactions, we try to explain the cases where existing methods may fall short. One obvious alternate approach would be to look at the network\u0026rsquo;s Hessian. While the network\u0026rsquo;s input Hessian contains information about the interaction between pairs of features, it suffers from the problem of saturation.\n  Neural Network with sigmoid activation representing an XOR function   For example, consider a neural network representation of an XOR function (which has been scaled between -10 and 10). This network is \u0026ldquo;on\u0026rdquo; when either one of the two binary-valued features have a value of 1, but \u0026ldquo;off\u0026rdquo; when both features are either 0 or 1. At every point on the data manifold the network\u0026rsquo;s output is saturated (flat), meaning that its gradients and Hessians will be 0. While there is clearly an interaction between the two features, simply considering the input Hessian completely fails to find the interaction.\nWith Integrated Hessians, we consider many points along the straight-line path between a baseline and the input we want to explain. While the gradients and Hessians are saturated on all of the data manifold points, we come across many places with well-defined curvature between these points. Integrated Hessians is therefore able to correctly detect the negative interaction between the two features. This negative interaction matches human intuition. Each feature contributes positively to the network\u0026rsquo;s output when turned on alone. When turned on together, however, the interaction cancels out the positive contribution of each feature\u0026rsquo;s individual contribution.\n  Integrated Hessians interactions for sigmoid XOR network   In addition to our approach and the input Hessian, there are a variety of other methods that have been proposed for finding feature interactions in machine learning models. These include the Shapley Interaction Index and the Shapley-Taylor Interaction Index, which, like our approach, have game-theoretic connections. Another set of approaches include methods based on Group Attributions, like Contextual Decomposition and the Archipelago framework.4 Finally, there are global feature interaction detection methods, which find interactions for an entire model rather than for specific predictions.\nWhile these are all good methods, our paper includes a more thorough discussion of the trade-offs between these different approaches. Our main takeaway is that Integrated Hessians strikes a good balance between computational efficiency and accuracy, especially for models with larger numbers of features.\n  Computation time required to get interactions   One weird trick to find interaction in ReLU networks\u0026hellip; If you were paying close attention earlier, you might have noticed an apparent problem with our method. While Integrated Hessians can get around the problem of saturation in neural networks by integrating over a path, there are a large subset of networks where it will be impossible to find curvature anywhere in the input space \u0026ndash; networks with ReLU activations. Since these networks are piecewise-linear, differentiating the model twice will always lead to values of 0. While this might sound like an impassable obstacle for our method, we found a smooth way to get around this issue.\nWhile a ReLU function has all 0 higher derivatives, it has a smooth approximation with very nicely defined higher derivatives \u0026ndash; the SoftPlus function: $\\textrm{SoftPlus}_{\\beta}(x) = \\frac{1}{\\beta}\\log (1 + e^{-\\beta x})$.\n  SoftPlus smoothly approximates ReLU   For example, consider the example5 of a single ReLU neuron with two input features, $f(x,y) = \\textrm{ReLU}(-\\frac{3x}{2} - 2y +2)$. We would hope to find a positive interaction between $x$ and $y$, since when both $x$ and $y$ have large values the network output is less negative than it would be if the function were additive. Unfortunately, since the ReLU network is piecewise-linear, it seems like Integrated Hessians will not find the interaction. If we apply Integrated Hessians to the SoftPlus approximation of this function, however, we see that Integrated Hessians can correctly identify the positive interaction between $x$ and $y$, in addition to the negative main effect for each feature.\n  Softplus Replacement for a single ReLU function. For large values of $\\beta$ in the SoftPlus function (20 in this case), the two functions are virtually indistinguishable.   While it\u0026rsquo;s nice to be able to explain this smooth approximation to a single neuron, what\u0026rsquo;s even more impressive is that this trick can be applied to an entire fully trained neural network. To explain a ReLU network, we can simply replace all of the ReLU activations with SoftPlus activations and explain the network with smooth activations (without any need to retrain).\nWe got this idea from this excellent paper on the geometry of neural network decision surfaces and the impact of this geometry on model explanation. Theoretically and empirically, this is a good approximation. One of my favorite results from our paper that I won\u0026rsquo;t really dig into here is that the smoother you make the approximation, the less samples along the interpolation path are necessary to get a good approximation to the \u0026ldquo;true\u0026rdquo; integral in Integrated Hessians.\n  The more you smooth the network, the more similar the gradients and Hessians along the interpolation path become.   Hyperbole and a Different Type of Saturation One cool aspect of interpreting models is that we often find that models have learned surprising relationships between features. For example, we took a Transformer model that had been fine-tuned to predict whether a movie review had a positive or negative sentiment. We then wrote a gratuitously negative movie review, and used Integrated Hessians to find the interactions learned by the model.\nOur review, \u0026ldquo;A bad, terrible, awful, horrible movie,\u0026rdquo; was of course predicted to have negative sentiment. Furthermore, each word gets an overwhelmingly negative first-order attribution. When we look at the interactions, however, we see something surprising.\nEach negative adjective in the phrase has a very slight positive interaction with the other negative adjectives. It seems that the model has learned a sort of saturation effect in the presence of hyperbolic speech \u0026ndash; when we combine all of the negative adjectives together, the model predicts a slightly less negative sentiment than we might expect if each word contributed negative sentiment independently. Whether this is desirable behavior reflecting real trends in the English language, or something the model learned in error, Integrated Hessians is able to reveal that the model has learned this trend at all. This highlights the benefit of examining feature interactions in models as opposed to just feature attributions. The attributions to the phrases and subphrases composing our review were all overwhelmingly negative. Examining the individual feature interactions shows an interesting trend that we wouldn\u0026rsquo;t have been able to find otherwise.\nConclusions From our investigation, we can see that there are meaningful and interesting interactions between features in neural networks \u0026ndash; Integrated Hessians can help us find them. While it was fun coming up with theoretical justifications in the paper for how nice our method is, one of our major goals is to actually make it usable for anyone who wants to find interaction in their own models! We encourage you to check out the GitHub repo (we now support TensorFlow 2 and PyTorch), and reach out to us with any and all questions and critiques about our method or software.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  from path_explain import PathExplainerTF ... Model training or loading code goes here ... explainer = PathExplainerTF(model) attributions = explainer.attributions(inputs=x_test, baseline=x_train, batch_size = 100, num_samples = 200, use_expectation = True, output_indices = 0) interactions = explainer.attributions(inputs=x_test, baseline=x_train, batch_size = 100, num_samples = 200, use_expectation = True, output_indices = 0)   ### Visualize interactions We've also included a plotting library to help visualize the attributions and interactions: --   Fig. 2 from the Archipelago paper. I guess they didn\u0026rsquo;t like our section on explaining ReLU networks 😭😭😭   At the end of the day, their approach goes after $\\\\phi$ while ours goes after $\\\\delta$. --   Emphasis on the word associated here. \u0026#x21a9;\u0026#xfe0e;\n Integrated Gradients is the unique method that fulfills a bunch of desirable axioms (and is closely connected to the Aumann-Shapley value), all of which you can read about in the paper proposing that method. \u0026#x21a9;\u0026#xfe0e;\n The logic behind naming our method Integrated Hessians becomes more obvious when we expand $ \\Gamma_{i,j} $: $$ \\Gamma_{i,j} = (x_i - x_i\u0026rsquo;)(x_j - x_j\u0026rsquo;) \\times \\int_{\\beta = 0}^{1}\\int_{\\alpha = 0}^{1} \\alpha \\beta \\frac{\\partial^2 f(x\u0026rsquo; + \\alpha \\beta(x - x\u0026rsquo;))}{\\partial x_i \\partial x_j}. $$ By directly computing the interpolated Hessians whenever possible instead of simply recursively applying integrated gradients to itself, we can take advantage of GPU acceleration to greatly increase our method\u0026rsquo;s efficiency. \u0026#x21a9;\u0026#xfe0e;\n More in a future blog post about this, but I think both of these approaches have a different notion of interaction than Integrated Hessians does. I would call their methods something more like \u0026ldquo;Group Attribution\u0026rdquo; than \u0026ldquo;Interaction\u0026rdquo; \u0026ndash; they both are concerned with attributing importance to interacting groups of features, while our method focuses on finding the magnitude and direction of the interactions between specific features. Their approaches aren\u0026rsquo;t any better or worse than ours, they just aim to answer a fundamentally different question and find a fundamentally different value (which is why their approaches do so poorly on the benchmarks we design, and ours probably do badly on the benchmarks they design). \u0026#x21a9;\u0026#xfe0e;\n This example borrowed from Fig. 2 of the Archipelago paper. Despite their objection in the caption to that figure, Integrated Hessians does apply to ReLU networks. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1594509915,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594509915,"objectID":"14709066aac42a8d9209651fe4e3cb27","permalink":"/post/integrated_hessians/","publishdate":"2020-07-11T19:25:15-04:00","relpermalink":"/post/integrated_hessians/","section":"post","summary":"An introduction to our new feature interaction method","tags":[],"title":"Finding interactions in deep neural networks with Integrated Hessians","type":"post"},{"authors":[],"categories":[],"content":"","date":1594317758,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594317758,"objectID":"2ff140a604003595b7425ab28106518b","permalink":"/project/path_explain/","publishdate":"2020-07-09T14:02:38-04:00","relpermalink":"/project/path_explain/","section":"project","summary":"A repository for explaining feature importances and feature interactions in deep neural networks using path attribution methods (Integrated Gradients and Integrated Hessians)","tags":[],"title":"Path Explainer","type":"project"},{"authors":[],"categories":[],"content":"","date":1593542387,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593542387,"objectID":"cc927cd431fed8c69c45c92f1214cc40","permalink":"/publication/integrated_hessians/","publishdate":"2020-07-09T14:39:47-04:00","relpermalink":"/publication/integrated_hessians/","section":"publication","summary":"Preprint (under review). An efficient and accurate method (Integrated Hessians) for detecting interactions in neural networks.","tags":[],"title":"Explaining Explanations: Axiomatic Feature Interactions for Deep Networks","type":"publication"},{"authors":[],"categories":[],"content":"","date":1585852772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585852772,"objectID":"7219d392f7bfb70e5c93c07f9e16c624","permalink":"/publication/cxr_adv/","publishdate":"2020-07-09T14:39:32-04:00","relpermalink":"/publication/cxr_adv/","section":"publication","summary":"Published in __Proceedings of the ACM Conference on Health, Inference, and Learning__ 2020.","tags":[],"title":"An adversarial approach for the robust classification of pneumonia from chest radiographs","type":"publication"},{"authors":[],"categories":[],"content":"","date":1577902235,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577902235,"objectID":"a2db8e7b4b543b563a328cdb636e7f06","permalink":"/project/cxr_adv/","publishdate":"2020-01-01T14:10:35-04:00","relpermalink":"/project/cxr_adv/","section":"project","summary":"A repository to train confounder-invariant deep learning models for chest radiographs","tags":[],"title":"De-confounded Pneumonia Classification","type":"project"},{"authors":[],"categories":[],"content":"","date":1575225631,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575225631,"objectID":"d6c8ca836fc392f3c0730c9f9d5eb30f","permalink":"/publication/dapr/","publishdate":"2020-07-09T14:40:31-04:00","relpermalink":"/publication/dapr/","section":"publication","summary":"Preprint (under review). A method for jointly learning a deep neural network and a flexible prior on the attributions of that model using meta-features.","tags":[],"title":"Learning Deep Attribution Priors Based On Prior Knowledge","type":"publication"},{"authors":[],"categories":[],"content":"","date":1559760045,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559760045,"objectID":"82631c7ff8b8d3172ca35f0c0a7d2c3c","permalink":"/publication/attribution_priors/","publishdate":"2020-07-09T14:40:45-04:00","relpermalink":"/publication/attribution_priors/","section":"publication","summary":"Preprint (under review). A method to regularize the attributions of neural networks during the training process.","tags":[],"title":"Learning explainable models using attribution priors","type":"publication"},{"authors":[],"categories":[],"content":"","date":1559413186,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559413186,"objectID":"615d2bc4a9f534df1a1b71d1a6c787b9","permalink":"/project/attribution_priors/","publishdate":"2019-06-01T14:19:46-04:00","relpermalink":"/project/attribution_priors/","section":"project","summary":"A repository with code to regularize a deep learning model's attributions during training in order to learn models with more desirable properties","tags":[],"title":"Attribution Priors","type":"project"},{"authors":[],"categories":[],"content":"","date":1538419254,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538419254,"objectID":"07f04b935f544cc86c1e219051e51bc5","permalink":"/publication/brca_sge/","publishdate":"2020-07-09T14:40:54-04:00","relpermalink":"/publication/brca_sge/","section":"publication","summary":"","tags":[],"title":"Accurate classification of BRCA1 variants with saturation genome editing","type":"publication"},{"authors":[],"categories":[],"content":"","date":1527878467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527878467,"objectID":"e18f4764e21b421065682bb109674aad","permalink":"/publication/express_workshop/","publishdate":"2020-07-09T14:41:07-04:00","relpermalink":"/publication/express_workshop/","section":"publication","summary":"","tags":[],"title":"Explainable machine learning prediction of synergistic drug combinations for precision cancer medicine","type":"publication"},{"authors":[],"categories":[],"content":"","date":1430505676,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430505676,"objectID":"80d91186433ec7772705a16a4a91d247","permalink":"/publication/lipase2/","publishdate":"2020-07-09T14:41:16-04:00","relpermalink":"/publication/lipase2/","section":"publication","summary":"","tags":[],"title":"Characterization of the Lipase Stimulating Domain for Apolipoprotein AV and the Development of a Therapeutic Peptide for the Treatment of Hypertriglyceridemia","type":"publication"},{"authors":[],"categories":[],"content":"","date":1398969678,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398969678,"objectID":"bc21f56ac48be4eb2cda93aa156f9767","permalink":"/publication/lipase1/","publishdate":"2020-07-09T14:41:18-04:00","relpermalink":"/publication/lipase1/","section":"publication","summary":"","tags":[],"title":"A Novel Fluorescence-Based Assay is Used to Investigate the Triglyceride Hydrolytic Activity of Lipases and to Identify Synthetic Peptides With Strong Lipase-Stimulating Activities","type":"publication"}]